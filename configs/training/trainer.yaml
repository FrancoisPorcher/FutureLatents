wandb: false
trainer:
  training:
    learning_rate: 1e-5
    weight_decay: 0.01
    num_workers: 8
    gradient_accumulation_steps: 1
    find_unused_parameters: true
    mixed_precision: fp16
    gradient_checkpointing: true
    max_grad_norm: 1.0
    max_grad_value: null
    epochs: 1
  evaluation:
    eval_every: 1
    eval_first: false
model:
  num_context_latents: 16
  flow_matching:
    num_train_timesteps: 1000
    dit:
      input_dim: 1024
      hidden_dim: 1024
      depth: 12
      num_heads: 8
      mlp_ratio: 4.0
