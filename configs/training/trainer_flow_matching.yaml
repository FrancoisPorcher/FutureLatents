wandb: True
encoder_trainable: false
trainer:
  training:
    learning_rate: 1e-5
    weight_decay: 0.01
    num_workers: 8
    batch_size_per_gpu: 1
    gradient_accumulation_steps: 1
    find_unused_parameters: true
    mixed_precision: fp16
    max_grad_norm: 1.0
    max_grad_value: null
    epochs: 1
    embedding_norm: l2
    loss: mse
  evaluation:
    eval_every: 1
    eval_first: false
    batch_size_per_gpu: 1
model:
  type: flow_matching
  num_context_latents: 16
  num_train_timesteps: 1000
  dit:
    input_dim: 1024
    hidden_dim: 1024
    depth: 12
    num_heads: 8
    mlp_ratio: 4.0
    gradient_checkpointing: true
